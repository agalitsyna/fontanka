import click
import click_log
from . import cli

import pandas as pd
import numpy as np
import scipy

import cooler
from cooltools.api import snipping
from ..lib import *

# Set up logging:
from . import get_logger

logger = get_logger(__name__)


@cli.command()
@click_log.simple_verbosity_option(logger)
@click.argument("cool_path", metavar="COOL_PATH", type=str)
@click.argument("output_path", metavar="OUTPUT_PATH", type=str)
@click.option(
    "--regions",
    "--view",
    help="Regions table, tsv file with chromosome, start, end in each line, no header.",
    type=str,
)
@click.option(
    "--window-size", "-W", help="Window size for fountains, in basepairs", type=int,
)
@click.option(
    "--mask", "-M", help="npy object with stored mask", type=str, default=None,
)
@click.option(
    "--measure",
    "-m",
    help="Name of measure for calculating similarity",
    type=str,
    default="corr",
)
@click.option(
    "--snips",
    "-S",
    help="npy object with stored whole-genome snips",
    type=str,
    default=None,
)
@click.option(
    "--nthreads",
    "-p",
    help="Number of threads to use for generating snips",
    type=int,
    default=1,
)
@click.option(
    "--store-snips",
    help="File for storing the snips. Will have .npy format.",
    type=str,
    default=None,
)
@click.option(
    "--expected",
    help="File with expected table, generated by cooltools. Required only if snips are not provided.",
    type=str,
    default=None,
    required=False,
)
def apply_fountain_mask(
    cool_path,
    output_path,
    regions,
    window_size,
    mask,
    snips,
    nthreads,
    store_snips,
    expected,
    measure,
):

    logger.info(
        f"""Running fountain calling for: {cool_path}, window size: {window_size}
        mask location:{mask}"""
    )

    # load cooler
    clr = cooler.Cooler(cool_path)
    bins = clr.bins()[:]
    resolution_bp = clr.binsize

    assert (
        window_size % resolution_bp == 0
    ), "Window size should be divisible by resolution"

    # load chromosome regions
    chroms_regions = pd.read_table(regions, header=None)
    if len(chroms_regions.columns) == 3:
        chroms_regions.columns = ["chrom", "start", "end"]
        chroms_regions.loc[:, "name"] = chroms_regions.apply(
            lambda x: f"{x.chrom}:{x.start}-{x.end}", axis=1
        )
    elif len(chroms_regions.columns) == 4:
        chroms_regions.columns = ["chrom", "start", "end", "name"]
    else:
        raise ValueError(
            "Regions table should have 3 or 4 columns and no header. Comply with Open2C viewframe format."
        )

    # create genome-wide windows:
    windows = snipping.make_bin_aligned_windows(
        resolution_bp, bins["chrom"], bins["start"], flank_bp=window_size
    )

    # Assign genomic regions to windows:
    windows = snipping.assign_view_auto(windows, chroms_regions).reset_index(drop=True)

    # Create and store the stack:
    if not snips is None:
        stack = read_snips(snips)
    else:
        if not expected is None:
            expected = pd.read_table(expected, header=0)
        stack = generate_ObsExpSnips(
            clr, windows, chroms_regions, expected=expected, nthreads=nthreads
        )
        # Store the stack:
        if not store_snips is None:
            save_snips(stack, store_snips)

    logger.info(f"Finished generating stack, stack shape:{stack.shape} ")

    # Read fountain mask:
    mask = np.load(mask)

    # Create track with metadata:
    # Similarity track:
    sim_track = generate_similarity_score(stack, mask, measure)
    # Scharr score track (for the whole window):
    scharr_track_box = generate_scharr_score(stack)

    # Write the result, note that bad bins are not filtered out:
    metadata = bins[["chrom", "start", "end"]].copy()
    metadata.loc[:, "window_start"] = windows["start"]
    metadata.loc[:, "window_end"] = windows["end"]
    # Fountain Score (FS) is an average OEE in the fountain divided by average OOE outside of it:
    metadata["FS"] = sim_track
    # Fountain peaks are the prominences of peaks:
    metadata["FS_peaks"] = metadata.groupby("chrom")["FS"].transform(
        get_peaks_prominence
    )
    # Average Scharr gor a box:
    metadata["Scharr_box"] = scharr_track_box

    ######################
    ### Store the dataset
    ######################
    logger.info(f"Writing generated metadata into: {output_path}")
    metadata.to_csv(output_path, sep="\t")
